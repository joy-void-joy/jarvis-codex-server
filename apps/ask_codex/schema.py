from __future__ import annotations

from graphql_jwt.decorators import login_required
import graphene
import openai
import transformers

from .prompts import VA, Verificator
from . import Anonymizer
import ast
from .history.models import Log

count_token = transformers.GPT2TokenizerFast.from_pretrained("gpt2")

class Query(graphene.ObjectType):
    _pass = graphene.Boolean()

class CodeResponse(graphene.ObjectType):
    class Code(graphene.ObjectType):
        answer = graphene.String(description="The code to execute to satisfy the command")
    code = graphene.Field(Code, description="The code generated by codex")

    class Description(graphene.ObjectType):
        answer = graphene.String(description="What the verificator think the Codex' code is doing")
        anonymized_code = graphene.String(description="The anonymized code from Codex passed to the verificator")

    description = graphene.Field(Description, description="Description of the generated code")

class DirectResponse(graphene.ObjectType):
    answer = graphene.String(description="What codex has answered directly (without code)")

class Response(graphene.Union):
    class Meta:
        types = (CodeResponse, DirectResponse)

class CreateCommand(graphene.Mutation):
    class Arguments:
        command = graphene.String(description="The command to execute")

    response = graphene.Field(Response, description="What codex has answered. Either code to execute, or a direct answer")
    direct = graphene.Boolean(description="Alternative to __typename")

    @login_required
    def mutate(root: None, info, command: str):
        nl = '\n'
        prompt = f"{VA.prompt}\n{nl.join(str(i) for i in Log.objects.filter(sent_by=info.context.user, active=True))}\n# Command: {command}\n"
        VA_answer = openai.Completion.create(
            engine="davinci-codex",
            max_tokens=1000,
            stop="# Command:",
            temperature=0,
            prompt=prompt,
            user=str(info.context.user.uuid),
        )
        code = VA_answer.choices[0].text

        log = Log.objects.create(
            sent_by=info.context.user,
            command=command,
            answer=code,
        )
        log.num_tokens = len(count_token(str(log)))


        anonymized = Anonymizer.anonymize(code)
        # Direct answer, no need for verification
        if anonymized == "return []":
            parsed = ast.parse(code)
            return CreateCommand(
                direct=True,
                response=DirectResponse(answer=ast.literal_eval(parsed.body[0].value)),
            )

        Verificator_answer = openai.Completion.create(
            engine="davinci-codex",
            max_tokens=20,
            stop=['\n', "==="],
            temperature=0,
            prompt=f"{Verificator.prompt}\n===\nQ:\n{anonymized}\nA:",
            user=str(info.context.user.uuid),
        )
        description = Verificator_answer.choices[0].text

        return CreateCommand(
            direct=False,
            response=CodeResponse(
                code=CodeResponse.Code(answer=code),
                description=CodeResponse.Description(answer=description, anonymized_code=anonymized),
            )
        )

class Clear(graphene.Mutation):
    _pass = graphene.Boolean()

    @login_required
    def mutate(root: None, info):
        Log.objects.filter(sent_by=info.context.user).update(active=False)
        return Clear(_pass=True)

class Mutation(graphene.ObjectType):
    create_command = CreateCommand.Field(description="Ask Codex to execute a command")
    clear = Clear.Field(description="Return to base prompt")

schema = graphene.Schema(query=Query, mutation=Mutation)
